Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 16
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	downloading_genomes
	1

[Sat Nov 26 17:52:26 2022]
rule downloading_genomes:
    output: database/list_of_genomes.txt
    jobid: 0

[Sat Nov 26 17:52:26 2022]
Error in rule downloading_genomes:
    jobid: 0
    output: database/list_of_genomes.txt
    shell:
        
        esearch -db assembly -query '"Bombus"[Organism] AND (latest[filter] AND all[filter] NOT anomalous[filter]) AND ("chromosome level"[filter] AND "representative genome"[filter])' \
        | esummary \
        | xtract -pattern DocumentSummary -element FtpPath_GenBank \
        | while read -r line ; 
        do
            fname=$(echo $line | grep -o 'GCA_.*' | sed 's/$/_genomic.fna.gz/') ;
            wget "$line/$fname" ;
        done


        ls *gz > list_of_genomes.txt

        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/amk/Desktop/Geronimo/GERONIMO/.snakemake/log/2022-11-26T175226.724721.snakemake.log
