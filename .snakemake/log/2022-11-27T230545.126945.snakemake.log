Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	make_queue
	1

[Sun Nov 27 23:05:45 2022]
rule make_queue:
    input: list_of_genomes.txt
    output: database/*.fna
    jobid: 0
    wildcards: GENOME=*



        GENOME=$(head -n 1 list_of_genomes.txt)

        tail -n +2 list_of_genomes.txt > "$FILE.tmp" && mv "$FILE.tmp" list_of_genomes.txt

        wget -P ./database "$GENOME"

        gunzip ./database/*.fna.gz

        
[Sun Nov 27 23:05:49 2022]
Error in rule make_queue:
    jobid: 0
    output: database/*.fna
    shell:
        

        GENOME=$(head -n 1 list_of_genomes.txt)

        tail -n +2 list_of_genomes.txt > "$FILE.tmp" && mv "$FILE.tmp" list_of_genomes.txt

        wget -P ./database "$GENOME"

        gunzip ./database/*.fna.gz

        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/amk/Desktop/Geronimo/GERONIMO/.snakemake/log/2022-11-27T230545.126945.snakemake.log
