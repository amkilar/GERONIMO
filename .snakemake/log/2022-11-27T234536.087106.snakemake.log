Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 16
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	download_genome
	1

[Sun Nov 27 23:45:36 2022]
rule download_genome:
    input: list_of_genomes.txt
    output: database/*.fna
    jobid: 0
    wildcards: GENOME=*



        GENOME=$(head -n 1 list_of_genomes.txt)



        wget -P ./database "$GENOME"

        gunzip ./database/*.gz

        tail -n +2 list_of_genomes.txt > "$FILE.tmp" && mv "$FILE.tmp" list_of_genomes.txt

        
[Sun Nov 27 23:46:35 2022]
Error in rule download_genome:
    jobid: 0
    output: database/*.fna
    shell:
        

        GENOME=$(head -n 1 list_of_genomes.txt)



        wget -P ./database "$GENOME"

        gunzip ./database/*.gz

        tail -n +2 list_of_genomes.txt > "$FILE.tmp" && mv "$FILE.tmp" list_of_genomes.txt

        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/amk/Desktop/Geronimo/GERONIMO/.snakemake/log/2022-11-27T234536.087106.snakemake.log
