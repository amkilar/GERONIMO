Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 16
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	download_genome
	1

[Mon Nov 28 00:14:54 2022]
rule download_genome:
    input: list_of_genomes.txt
    output: database/*.fna
    jobid: 0
    wildcards: GENOME=*



        GENOME=$(head -n 1 list_of_genomes.txt)

        tail -n +2 list_of_genomes.txt > "FILE.tmp" && mv "FILE.tmp" list_of_genomes.txt


        wget -P ./database "$GENOME" -o tmp.gz

        sleep 0.01

        gunzip ./database/tpm.gz

        #tail -n +2 list_of_genomes.txt > "$FILE.tmp" && mv "$FILE.tmp" list_of_genomes.txt

        
Terminating processes on user request, this might take some time.
[Mon Nov 28 00:15:19 2022]
Error in rule download_genome:
    jobid: 0
    output: database/*.fna
    shell:
        

        GENOME=$(head -n 1 list_of_genomes.txt)

        tail -n +2 list_of_genomes.txt > "FILE.tmp" && mv "FILE.tmp" list_of_genomes.txt


        wget -P ./database "$GENOME" -o tmp.gz

        sleep 0.01

        gunzip ./database/tpm.gz

        #tail -n +2 list_of_genomes.txt > "$FILE.tmp" && mv "$FILE.tmp" list_of_genomes.txt

        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: /home/amk/Desktop/Geronimo/GERONIMO/.snakemake/log/2022-11-28T001453.990899.snakemake.log
